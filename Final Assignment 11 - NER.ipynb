{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5eaddd83",
   "metadata": {},
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac15a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas spacy networkx matplotlib beautifulsoup4\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12144293",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dbe817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('teachers_db_practice.csv')\n",
    "def clean_html(text):\n",
    "    if isinstance(text, str):\n",
    "        return BeautifulSoup(text, 'html.parser').get_text()\n",
    "    return text\n",
    "\n",
    "df['cleaned_info'] = df['full_info'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590233d1",
   "metadata": {},
   "source": [
    "# 3. Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075b6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_lg')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66965585",
   "metadata": {},
   "source": [
    "### Define a function to extract the entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87b8bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_entity_text(text):\n",
    "    \"\"\"Helper function to clean and normalize a single entity string.\"\"\"\n",
    "    # Remove common prefixes/suffixes and extra whitespace\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'•\\s*', '', text) # Remove bullet points\n",
    "    text = re.sub(r'Academic Background', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'Corporate Experience', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r', (USA|Spain|U\\.K\\.|Belgium)', '', text) # Remove country suffices\n",
    "    text = text.strip('•, ')\n",
    "    return text\n",
    "\n",
    "def extract_and_clean_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {'UNIVERSITY': set(), 'STUDY': set(), 'COMPANY': set(), 'COURSE': set()}\n",
    "\n",
    "    # --- 1. Extract Universities and Companies using spaCy's ORG label ---\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            cleaned_text = clean_entity_text(ent.text)\n",
    "            if 'University' in cleaned_text or 'College' in cleaned_text or 'School' in cleaned_text or 'Institute' in cleaned_text or 'Universidad' in cleaned_text:\n",
    "                entities['UNIVERSITY'].add(cleaned_text)\n",
    "            # Add a length check to avoid fragments like \"EU\"\n",
    "            elif len(cleaned_text) > 3 and \"experience\" not in cleaned_text.lower(): \n",
    "                entities['COMPANY'].add(cleaned_text)\n",
    "\n",
    "    # --- 2. Extract Studies using precise Regular Expressions ---\n",
    "    # Pattern to find degrees like \"Master in X\", \"Ph.D. in Y\", \"Bachelor of Z\"\n",
    "    study_pattern = re.compile(r'\\b(Master|Bachelor|Ph\\.D\\.|M\\.A\\.|B\\.S\\.|M\\.B\\.A\\.|E\\.M\\.B\\.A\\.)\\s*(in|of|degree in)?\\s*([\\w\\s,&]+?)(?=\\s*,|\\s*\\d{4}|\\s*•)')\n",
    "    matches = study_pattern.finditer(text)\n",
    "    for match in matches:\n",
    "        # Combine the degree type (e.g., \"Master\") with the field (e.g., \"Graphic Design\")\n",
    "        full_study = f\"{match.group(1)} in {match.group(3).strip()}\"\n",
    "        entities['STUDY'].add(clean_entity_text(full_study))\n",
    "\n",
    "    # --- 3. Extract Courses ---\n",
    "    # (This can be further refined if needed)\n",
    "    course_keywords = ['course on', 'program in', 'lectures on', 'teaches']\n",
    "    for keyword in course_keywords:\n",
    "        if keyword in text:\n",
    "            for sent in doc.sents:\n",
    "                if keyword in sent.text:\n",
    "                     # Split the sentence at the keyword and take the second part\n",
    "                     course_name = sent.text.split(keyword, 1)[1].strip().split(',')[0]\n",
    "                     entities['COURSE'].add(clean_entity_text(course_name))\n",
    "\n",
    "    # Convert sets back to lists for consistency\n",
    "    return {k: list(v) for k, v in entities.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108aff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['entities'] = df['cleaned_info'].apply(extract_and_clean_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f24173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the entities extracted for the first 5 professors\n",
    "for index, row in df.head().iterrows():\n",
    "    print(f\"Entities for {row['alias']}:\")\n",
    "    print(row['entities'])\n",
    "    print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00806db3",
   "metadata": {},
   "source": [
    "# 4. Social Network Analysis (SNA) with NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4639c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-create the graph with cleaned data\n",
    "G_cleaned = nx.Graph()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    professor_alias = row['alias']\n",
    "    G_cleaned.add_node(professor_alias, type='professor')\n",
    "\n",
    "    entities = row['entities']\n",
    "    for university in entities['UNIVERSITY']:\n",
    "        # This now adds a single, clean node for each university\n",
    "        G_cleaned.add_node(university, type='university')\n",
    "        G_cleaned.add_edge(professor_alias, university, relation='affiliated_with')\n",
    "\n",
    "    for company in entities['COMPANY']:\n",
    "        G_cleaned.add_node(company, type='company')\n",
    "        G_cleaned.add_edge(professor_alias, company, relation='worked_at')\n",
    "\n",
    "    for study in entities['STUDY']:\n",
    "        G_cleaned.add_node(study, type='study')\n",
    "        G_cleaned.add_edge(professor_alias, study, relation='studied')\n",
    "\n",
    "    for course in entities['COURSE']:\n",
    "        G_cleaned.add_node(course, type='course')\n",
    "        G_cleaned.add_edge(professor_alias, course, relation='teaches')\n",
    "\n",
    "# Visualize the new, cleaner graph\n",
    "plt.figure(figsize=(20, 20))\n",
    "pos = nx.spring_layout(G_cleaned, k=0.6, iterations=50)\n",
    "\n",
    "# Define colors for the node types\n",
    "node_colors_map = {\n",
    "    'professor': 'red', \n",
    "    'university': 'blue', \n",
    "    'company': 'green', \n",
    "    'study': 'purple', \n",
    "    'course': 'orange'\n",
    "}\n",
    "node_colors = [node_colors_map.get(G_cleaned.nodes[node]['type'], 'grey') for node in G_cleaned.nodes()]\n",
    "\n",
    "# nx.draw(G_cleaned, pos, with_labels=True, node_color=node_colors, node_size=1500, font_size=8, alpha=0.7)\n",
    "# plt.title('Cleaned and Normalized Knowledge Graph')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f7a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list to hold all the connections (edges)\n",
    "edge_list = []\n",
    "\n",
    "# Loop through every edge in your cleaned graph\n",
    "# data=True fetches the attributes we added (like 'relation')\n",
    "for source, target, data in G_cleaned.edges(data=True):\n",
    "    edge_list.append({\n",
    "        \"Source\": source,\n",
    "        \"Relationship\": data['relation'],\n",
    "        \"Target\": target\n",
    "    })\n",
    "\n",
    "# Convert the list of connections into a DataFrame\n",
    "graph_table = pd.DataFrame(edge_list)\n",
    "\n",
    "# Display the full table\n",
    "print(\"Graph 'G_cleaned' represented as a table:\")\n",
    "pd.set_option('display.max_rows', None) # Show all rows\n",
    "pd.set_option('display.max_colwidth', None) # Show full text in columns\n",
    "display(graph_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1dd529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Graph Information\n",
    "num_nodes = G_cleaned.number_of_nodes()\n",
    "num_edges = G_cleaned.number_of_edges()\n",
    "print(f\"Number of nodes: {num_nodes}\")\n",
    "print(f\"Number of edges: {num_edges}\")\n",
    "\n",
    "# Check if the graph is connected\n",
    "is_connected = nx.is_connected(G_cleaned)\n",
    "print(f\"Is the graph connected? {is_connected}\")\n",
    "\n",
    "# If not connected, find the number of connected components\n",
    "if not is_connected:\n",
    "    num_components = nx.number_connected_components(G_cleaned)\n",
    "    print(f\"Number of connected components: {num_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a33d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Degree Centrality: Number of connections a node has\n",
    "degree_centrality = nx.degree_centrality(G_cleaned)\n",
    "sorted_degree = sorted(degree_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Top 5 nodes by Degree Centrality:\")\n",
    "for node, centrality in sorted_degree[:5]:\n",
    "    print(f\"- {node}: {centrality:.4f}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Betweenness Centrality: How often a node lies on the shortest path between other nodes\n",
    "betweenness_centrality = nx.betweenness_centrality(G_cleaned)\n",
    "sorted_betweenness = sorted(betweenness_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Top 5 nodes by Betweenness Centrality:\")\n",
    "for node, centrality in sorted_betweenness[:5]:\n",
    "    print(f\"- {node}: {centrality:.4f}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Eigenvector Centrality: Influence of a node in the network\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G_cleaned, max_iter=1000) # Increased max_iter to ensure convergence\n",
    "sorted_eigenvector = sorted(eigenvector_centrality.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Top 5 nodes by Eigenvector Centrality:\")\n",
    "for node, centrality in sorted_eigenvector[:5]:\n",
    "    print(f\"- {node}: {centrality:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23af69d3",
   "metadata": {},
   "source": [
    "# 4.1 Subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e232544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_subgraph(sub_graph, pos, node_colors_map, title):\n",
    "    \"\"\"Helper function to draw a subgraph with correct colors and labels.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Get the colors for the nodes in this specific subgraph\n",
    "    sub_node_colors = [node_colors_map.get(sub_graph.nodes[node]['type'], 'grey') for node in sub_graph.nodes()]\n",
    "    \n",
    "    nx.draw(sub_graph, pos, with_labels=True, node_color=sub_node_colors, node_size=2000, font_size=10, alpha=0.8)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bdecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top node from your sorted degree list\n",
    "top_degree_node = sorted_degree[0][0]\n",
    "\n",
    "# Create an \"ego graph\" for this node. This includes the node and all its direct neighbors.\n",
    "ego_graph = nx.ego_graph(G_cleaned, top_degree_node)\n",
    "\n",
    "# Use a spring layout for this subgraph\n",
    "pos = nx.spring_layout(ego_graph, k=0.8)\n",
    "\n",
    "plot_subgraph(ego_graph, pos, node_colors_map, f\"Ego Network for Most Connected Node: {top_degree_node}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b915f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the top node from your sorted betweenness list\n",
    "top_broker_node = sorted_betweenness[0][0]\n",
    "\n",
    "# Create an \"ego graph\" for this node\n",
    "broker_ego_graph = nx.ego_graph(G_cleaned, top_broker_node)\n",
    "\n",
    "# Use a spring layout\n",
    "pos = nx.spring_layout(broker_ego_graph, k=0.8)\n",
    "\n",
    "plot_subgraph(broker_ego_graph, pos, node_colors_map, f\"Ego Network for Top 'Broker' Node: {top_broker_node}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49112dab",
   "metadata": {},
   "source": [
    "## But IE University and IE Business School are obviously the most connected nodes so let's ommit them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9843da97",
   "metadata": {},
   "source": [
    "# 5. Analysis of Filtered Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b735d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a deep copy of the cleaned graph to work with\n",
    "G_filtered = G_cleaned.copy()\n",
    "\n",
    "# Define the nodes to remove\n",
    "nodes_to_remove = ['IE University', 'IE Business School']\n",
    "\n",
    "# We should check which of these nodes actually exist in the graph before trying to remove them\n",
    "existing_nodes_to_remove = [node for node in nodes_to_remove if G_filtered.has_node(node)]\n",
    "\n",
    "if existing_nodes_to_remove:\n",
    "    print(f\"Removing the following nodes: {existing_nodes_to_remove}\")\n",
    "    G_filtered.remove_nodes_from(existing_nodes_to_remove)\n",
    "else:\n",
    "    print(\"Nodes to remove were not found in the graph.\")\n",
    "\n",
    "print(f\"\\nOriginal graph node count: {G_cleaned.number_of_nodes()}\")\n",
    "print(f\"Filtered graph node count: {G_filtered.number_of_nodes()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12862bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Re-run Numerical Analysis on the FILTERED Graph ---\n",
    "\n",
    "print(\"--- Analysis of Filtered Graph ---\")\n",
    "\n",
    "# Degree Centrality\n",
    "degree_centrality_f = nx.degree_centrality(G_filtered)\n",
    "sorted_degree_f = sorted(degree_centrality_f.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Top 5 nodes by Degree Centrality (Filtered):\")\n",
    "for node, centrality in sorted_degree_f[:5]:\n",
    "    print(f\"- {node}: {centrality:.4f}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Betweenness Centrality\n",
    "betweenness_centrality_f = nx.betweenness_centrality(G_filtered)\n",
    "sorted_betweenness_f = sorted(betweenness_centrality_f.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Top 5 nodes by Betweenness Centrality (Filtered):\")\n",
    "for node, centrality in sorted_betweenness_f[:5]:\n",
    "    print(f\"- {node}: {centrality:.4f}\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# Eigenvector Centrality\n",
    "eigenvector_centrality_f = nx.eigenvector_centrality(G_filtered, max_iter=1000)\n",
    "sorted_eigenvector_f = sorted(eigenvector_centrality_f.items(), key=lambda item: item[1], reverse=True)\n",
    "print(\"Top 5 nodes by Eigenvector Centrality (Filtered):\")\n",
    "for node, centrality in sorted_eigenvector_f[:5]:\n",
    "    print(f\"- {node}: {centrality:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4c4887",
   "metadata": {},
   "source": [
    "# 6. Subgraph Visualizations (Filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting\n",
    "def plot_subgraph(sub_graph, pos, node_colors_map, title):\n",
    "    \"\"\"Helper function to draw a subgraph with correct colors and labels.\"\"\"\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Get the colors for the nodes in this specific subgraph\n",
    "    sub_node_colors = [node_colors_map.get(sub_graph.nodes[node]['type'], 'grey') for node in sub_graph.nodes()]\n",
    "    \n",
    "    nx.draw(sub_graph, pos, with_labels=True, node_color=sub_node_colors, node_size=2000, font_size=10, alpha=0.8)\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a1603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique set of all the top nodes you found\n",
    "nodes_to_visualize = [\n",
    "    # Top 5 Degree\n",
    "    'Business Administration',\n",
    "    'Appius Licinius Cicero',\n",
    "    'Horatia Pulchra',\n",
    "    'Universidad Autónoma de Madrid',\n",
    "    'Marcus Fabius Crassus',\n",
    "    \n",
    "    # Top 5 Betweenness\n",
    "    'Harvard University',\n",
    "    'IE Law School',\n",
    "    'Universidad Complutense de Madrid',\n",
    "    \n",
    "    # Top 5 Eigenvector\n",
    "    'Bachelor in Business Administration',\n",
    "    'IESE',\n",
    "    'Gaius Julius Scipio'\n",
    "]\n",
    "\n",
    "# Loop through each node and plot its ego network\n",
    "for node_name in nodes_to_visualize:\n",
    "    # First, check if the node actually exists in our filtered graph\n",
    "    if not G_filtered.has_node(node_name):\n",
    "        print(f\"Node '{node_name}' not found in the filtered graph. Skipping.\")\n",
    "        print(\"-\" * 30)\n",
    "        continue\n",
    "    \n",
    "    # Create the ego graph\n",
    "    ego_graph = nx.ego_graph(G_filtered, node_name)\n",
    "    \n",
    "    # Use a spring layout\n",
    "    pos = nx.spring_layout(ego_graph, k=0.8, iterations=50)\n",
    "    \n",
    "    # Plot the subgraph using our helper function\n",
    "    plot_subgraph(ego_graph, pos, node_colors_map, f\"Ego Network for: {node_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7a38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Cell: Export Interactive Graphs to HTML ---\n",
    "\n",
    "# 1. Install pyvis (uncomment the line below if you haven't installed it)\n",
    "# !pip install pyvis\n",
    "\n",
    "from pyvis.network import Network\n",
    "import re\n",
    "\n",
    "# 2. Define the color map for pyvis (using HTML hex codes)\n",
    "pyvis_color_map = {\n",
    "    'professor': '#FF0000', \n",
    "    'university': '#0000FF', \n",
    "    'company': '#008000', \n",
    "    'study': '#800080', \n",
    "    'course': '#FFA500',\n",
    "    'other': '#808080'\n",
    "}\n",
    "\n",
    "# 3. List of nodes to export (copied from your analysis)\n",
    "nodes_to_visualize = [\n",
    "    # Top 5 Degree\n",
    "    'Business Administration',\n",
    "    'Appius Licinius Cicero',\n",
    "    'Horatia Pulchra',\n",
    "    'Universidad Autónoma de Madrid',\n",
    "    'Marcus Fabius Crassus',\n",
    "    \n",
    "    # Top 5 Betweenness\n",
    "    'Harvard University',\n",
    "    'IE Law School',\n",
    "    'Universidad Complutense de Madrid',\n",
    "    \n",
    "    # Top 5 Eigenvector\n",
    "    'Bachelor in Business Administration',\n",
    "    'IESE',\n",
    "    'Gaius Julius Scipio'\n",
    "]\n",
    "\n",
    "print(\"Starting export of interactive HTML graphs...\")\n",
    "\n",
    "# 4. Loop through each node, create graph, and save to HTML\n",
    "for node_name in nodes_to_visualize:\n",
    "    if not G_filtered.has_node(node_name):\n",
    "        print(f\"Skipping '{node_name}': Node not found in the filtered graph.\")\n",
    "        continue\n",
    "\n",
    "    # Create the ego graph from the filtered network\n",
    "    ego_graph = nx.ego_graph(G_filtered, node_name)\n",
    "    \n",
    "    # Create a pyvis network\n",
    "    plot_title = f\"Interactive Ego Network for: {node_name}\"\n",
    "    nt = Network(height='800px', width='100%', notebook=True, heading=plot_title)\n",
    "\n",
    "    # Convert the networkx ego_graph to a pyvis graph\n",
    "    nt.from_nx(ego_graph)\n",
    "    \n",
    "    # Manually set colors and titles (for hover info)\n",
    "    for node in nt.nodes:\n",
    "        node_id = node['id']\n",
    "        node_type = G_filtered.nodes[node_id].get('type', 'other')\n",
    "        node['color'] = pyvis_color_map.get(node_type, '#808080')\n",
    "        node['title'] = f\"Type: {node_type}\" # Tooltip on hover\n",
    "\n",
    "    # Create a safe filename\n",
    "    safe_filename = re.sub(r'[^\\w\\s-]', '', node_name).strip().replace(' ', '_')\n",
    "    filename = f\"interactive_ego_network_{safe_filename}.html\"\n",
    "    \n",
    "    # Save the interactive HTML file\n",
    "    nt.save_graph(filename)\n",
    "    print(f\"Successfully saved: {filename}\")\n",
    "\n",
    "print(\"--- Export Complete ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
